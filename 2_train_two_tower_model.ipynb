{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Tower Model 학습 시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature 테이블에서 데이터 읽어와서 train/test set으로 split 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/b8s33_bs1nx_2nnz6h7w64qm0000gn/T/ipykernel_24648/1062528239.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  retrievals_df = pd.read_sql('SELECT * FROM rec_retrievals', con=db_connection)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>age</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>index_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1537401600000000000</td>\n",
       "      <td>0095c9b47fc950788bb709201f024c5338838a27c59c02...</td>\n",
       "      <td>710390001</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537401600000000000</td>\n",
       "      <td>0095c9b47fc950788bb709201f024c5338838a27c59c02...</td>\n",
       "      <td>633130019</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1537401600000000000</td>\n",
       "      <td>0095c9b47fc950788bb709201f024c5338838a27c59c02...</td>\n",
       "      <td>671057002</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Divided</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t_dat                                        customer_id  \\\n",
       "0  1537401600000000000  0095c9b47fc950788bb709201f024c5338838a27c59c02...   \n",
       "1  1537401600000000000  0095c9b47fc950788bb709201f024c5338838a27c59c02...   \n",
       "2  1537401600000000000  0095c9b47fc950788bb709201f024c5338838a27c59c02...   \n",
       "\n",
       "  article_id     price  sales_channel_id  month_sin  month_cos   age  \\\n",
       "0  710390001  0.019051                 1  -0.866025       -0.5  20.0   \n",
       "1  633130019  0.016932                 1  -0.866025       -0.5  20.0   \n",
       "2  671057002  0.008458                 1  -0.866025       -0.5  20.0   \n",
       "\n",
       "  garment_group_name index_group_name  \n",
       "0             Skirts          Divided  \n",
       "1       Jersey Fancy          Divided  \n",
       "2       Jersey Fancy          Divided  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mysql.connector as sql\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "host = 'ssm-develop.db.sinsang.market'\n",
    "port = 3306\n",
    "username = 'dealicious'\n",
    "password = 'tlstkd12!@'\n",
    "database_name = 'dealicious'\n",
    "\n",
    "db_connection = sql.connect(host=host, database=database_name, user=username, password=password)\n",
    "\n",
    "retrievals_df = pd.read_sql('SELECT * FROM rec_retrievals', con=db_connection)\n",
    "\n",
    "retrievals_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(retrievals_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"article_id\"] = train_df[\"article_id\"].astype(str)  # to be removed\n",
    "test_df[\"article_id\"] = test_df[\"article_id\"].astype(str)  # to be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas dataframe 을 tensorflow dataset 으로 변환하기\n",
    "\n",
    "query embedding에 사용할 feature\n",
    "- `customer_id`: ID of the customer.\n",
    "- `age`: age of the customer at the time of purchase.\n",
    "- `month_sin`, `month_cos`: time of year the purchase was made.\n",
    "\n",
    "candidate embedding에 사용할 feature\n",
    "- `article_id`: ID of the item.\n",
    "- `garment_group_name`: type of garment.\n",
    "- `index_group_name`: menswear/ladieswear etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "query_features = [\"customer_id\", \"age\", \"month_sin\", \"month_cos\"]\n",
    "candidate_features = [\"article_id\", \"garment_group_name\", \"index_group_name\"]\n",
    "\n",
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col : df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 448\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "val_ds = df_to_ds(test_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 14,784\n",
      "Number of users: 3,845\n",
      "Number of items: 6,487\n",
      "['Jersey Fancy', 'Jersey Basic', 'Accessories', 'Knitwear', 'Trousers Denim', 'Socks and Tights', 'Special Offers', 'Under-, Nightwear', 'Blouses', 'Skirts', 'Trousers', 'Unknown', 'Swimwear', 'Shoes', 'Outdoor', 'Dresses/Skirts girls', 'Dressed', 'Dresses Ladies', 'Woven/Jersey/Knitted mix Baby', 'Shirts', 'Shorts']\n"
     ]
    }
   ],
   "source": [
    "user_id_list = train_df[\"customer_id\"].unique().tolist()\n",
    "item_id_list = train_df[\"article_id\"].unique().tolist()\n",
    "\n",
    "garment_group_list = train_df[\"garment_group_name\"].unique().tolist()\n",
    "index_group_list = train_df[\"index_group_name\"].unique().tolist()\n",
    "\n",
    "print(f\"Number of transactions: {len(train_df):,}\")\n",
    "print(f\"Number of users: {len(user_id_list):,}\")\n",
    "print(f\"Number of items: {len(item_id_list):,}\")\n",
    "print(garment_group_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Two Tower Model 학습\n",
    "\n",
    "다음의 두 모델을 two tower 학습 기법을 통해 학습 시킴.\n",
    "\n",
    "- `query model` : user, transaction feature를 나타내는 query embedding 생성하는 모델\n",
    "- `candidate model` : item feature를 나타내는 candidate embedding을 생성하는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ShuffleDataset element_spec={'t_dat': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'customer_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'article_id': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'price': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'sales_channel_id': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'month_sin': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'month_cos': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'age': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'garment_group_name': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'index_group_name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 14:39:01.745899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype double and shape [14784]\n",
      "\t [[{{node Placeholder/_6}}]]\n",
      "2024-05-02 14:39:01.746681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype double and shape [14784]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-05-02 14:39:02.040674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [14784]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 0.09135035,  0.20549442, -0.4943238 ,  0.09084118,  0.2652784 ,\n",
       "        -0.24944875, -0.11205667, -0.26309502, -0.19768474,  0.01405196,\n",
       "        -0.16555972,  0.30976024, -0.0327182 , -0.23440479,  0.0403135 ,\n",
       "         0.17018674]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.query_tower import QueryTower\n",
    "\n",
    "query_model = QueryTower(user_id_list=user_id_list, emb_dim=EMB_DIM)\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_df = train_df[query_features]\n",
    "query_ds = df_to_ds(query_df).batch(1)\n",
    "query_model(next(iter(query_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/b8s33_bs1nx_2nnz6h7w64qm0000gn/T/ipykernel_24648/2937662747.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from models.item_tower import ItemTower\n",
    "\n",
    "\n",
    "item_model = ItemTower(item_id_list=item_id_list, garment_group_list=garment_group_list, index_group_list=index_group_list, emb_dim=EMB_DIM)\n",
    "\n",
    "item_df = train_df[candidate_features]\n",
    "item_df.drop_duplicates(subset=\"article_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimin/study/two-tower/.venv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from models.two_tower_model import TwoTowerModel\n",
    "\n",
    "model = TwoTowerModel(query_model=query_model, item_model=item_model, item_ds=item_ds)\n",
    "optimizer = tfa.optimizers.AdamW(0.001, learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 14:39:16.202678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype double and shape [14784]\n",
      "\t [[{{node Placeholder/_7}}]]\n",
      "2024-05-02 14:39:16.203314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype int64 and shape [14784]\n",
      "\t [[{{node Placeholder/_8}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/33 [==========================>...] - ETA: 0s - loss: 2690.0121 - regularization_loss: 0.0000e+00 - total_loss: 2690.0121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 14:39:17.941503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype int64 and shape [3697]\n",
      "\t [[{{node Placeholder/_8}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 2s 22ms/step - loss: 2678.3572 - regularization_loss: 0.0000e+00 - total_loss: 2678.3572 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 499.9956 - val_regularization_loss: 0.0000e+00 - val_total_loss: 499.9956\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 2413.8755 - regularization_loss: 0.0000e+00 - total_loss: 2413.8755 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 490.5154 - val_regularization_loss: 0.0000e+00 - val_total_loss: 490.5154\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 2137.6981 - regularization_loss: 0.0000e+00 - total_loss: 2137.6981 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 522.5098 - val_regularization_loss: 0.0000e+00 - val_total_loss: 522.5098\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 1863.5304 - regularization_loss: 0.0000e+00 - total_loss: 1863.5304 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 546.2348 - val_regularization_loss: 0.0000e+00 - val_total_loss: 546.2348\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 1648.0977 - regularization_loss: 0.0000e+00 - total_loss: 1648.0977 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 607.1997 - val_regularization_loss: 0.0000e+00 - val_total_loss: 607.1997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172780ee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<models.two_tower_model.TwoTowerModel object at 0x1561ebd00>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModelModule(tf.Module):\n",
    "    def __init__(self, query_model):\n",
    "        self.query_model = query_model\n",
    "\n",
    "    @tf.function()\n",
    "    def compute_emb(self, instances):\n",
    "        query_emb = self.query_model(instances)\n",
    "        return {\"customer_id\": instances[\"customer_id\"],\n",
    "                \"month_sin\": instances[\"month_sin\"],\n",
    "                \"month_cos\": instances[\"month_cos\"],\n",
    "                \"query_emb\": query_emb}\n",
    "\n",
    "# wrap query_model:   query_model -> query_model_module\n",
    "query_model = QueryModelModule(model.query_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_model/assets\n"
     ]
    }
   ],
   "source": [
    "instances_spec={\n",
    "    'customer_id': tf.TensorSpec(shape=(None,), dtype=tf.string, name='customer_id'),\n",
    "    'month_sin': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='month_sin'),\n",
    "    'month_cos': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='month_cos'),\n",
    "    'age': tf.TensorSpec(shape=(None,), dtype=tf.float64, name='age')\n",
    "}\n",
    "signatures = query_model.compute_emb.get_concrete_function(instances_spec)\n",
    "\n",
    "tf.saved_model.save(query_model, \"query_model\", signatures=signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model.item_model, \"candidate_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'month_sin': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.1, 0.2])>, 'query_emb': <tf.Tensor: shape=(2, 16), dtype=float32, numpy=\n",
      "array([[-0.01002674,  0.1559282 ,  0.20848864, -0.29459476, -0.05245731,\n",
      "         0.02505475, -0.40152204, -0.5368727 ,  0.10836559,  0.29850647,\n",
      "        -0.55662155,  0.15531695, -0.18558472,  0.05173267,  0.27168903,\n",
      "        -0.3877893 ],\n",
      "       [-0.1436327 ,  0.19334501,  0.18951917, -0.31433272, -0.2350296 ,\n",
      "         0.14532247, -0.26973787, -0.20852515,  0.2952414 , -0.19411935,\n",
      "        -0.13977264,  0.14159653, -0.22866179,  0.02863191, -0.23835948,\n",
      "        -0.06198785]], dtype=float32)>, 'customer_id': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'customer1', b'customer2'], dtype=object)>, 'month_cos': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.2, 0.3])>}\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "loaded_model = tf.saved_model.load(\"query_model\")\n",
    "\n",
    "# 예측 함수 추출\n",
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "# 입력 스펙 확인\n",
    "# print(infer.structured_input_signature)\n",
    "\n",
    "# 샘플 입력 데이터 생성 (double 타입으로)\n",
    "sample_input = {\n",
    "    'customer_id': tf.constant(['customer1', 'customer2']),\n",
    "    'month_sin': tf.constant([0.1, 0.2], dtype=tf.float64),\n",
    "    'month_cos': tf.constant([0.2, 0.3], dtype=tf.float64),\n",
    "    'age': tf.constant([30.0, 40.0], dtype=tf.float64)\n",
    "}\n",
    "\n",
    "# 예측 수행\n",
    "predictions = infer(**sample_input)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '5TKGWRAEY1GESDNF', 'HostId': 'UeNCHD4Qm9w88G7SPkA/fb5z0rjua4AcOHxIVOTzLKAhRK0X0+BDsIQ2Ldm9Gd9bGLiHo/Tmf8w=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'UeNCHD4Qm9w88G7SPkA/fb5z0rjua4AcOHxIVOTzLKAhRK0X0+BDsIQ2Ldm9Gd9bGLiHo/Tmf8w=', 'x-amz-request-id': '5TKGWRAEY1GESDNF', 'date': 'Thu, 02 May 2024 06:14:01 GMT', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'Buckets': [{'Name': 'jimin-model', 'CreationDate': datetime.datetime(2024, 4, 22, 10, 46, 4, tzinfo=tzutc())}], 'Owner': {'ID': '3da57189eb51f3b76f1ecb9eb6413d9dfc082c729fcb356bb25a368d6921add5'}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "AWS_PROFILE = 'default'\n",
    "session = boto3.Session(profile_name=AWS_PROFILE)\n",
    "s3_client = session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = 'candidate_model'\n",
    "bucket = 'jimin_model'\n",
    "key = 'two-tower'\n",
    "s3_client.upload_file(local_model_path, bucket, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded query_model.tar.gz to s3://jimin-model/two-tower/query_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import boto3\n",
    "\n",
    "def make_tar_gz(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "def upload_to_s3(local_file_path, bucket_name, s3_file_path):\n",
    "    s3_client.upload_file(local_file_path, bucket_name, s3_file_path)\n",
    "\n",
    "def zip_and_upload_to_s3(local_directory, bucket_name, s3_directory):\n",
    "    # 로컬 디렉토리를 tar.gz로 압축\n",
    "    tar_gz_filename = local_directory + \".tar.gz\"\n",
    "    make_tar_gz(tar_gz_filename, local_directory)\n",
    "\n",
    "    # S3에 업로드할 경로 설정\n",
    "    s3_file_path = os.path.join(s3_directory, os.path.basename(tar_gz_filename))\n",
    "\n",
    "    # 압축 파일을 S3로 업로드\n",
    "    upload_to_s3(tar_gz_filename, bucket_name, s3_file_path)\n",
    "\n",
    "    # 압축 파일 삭제\n",
    "    os.remove(tar_gz_filename)\n",
    "    print(f\"Uploaded {tar_gz_filename} to s3://{bucket_name}/{s3_file_path}\")\n",
    "\n",
    "# 로컬 디렉토리 경로\n",
    "local_directory = \"query_model\"\n",
    "\n",
    "# S3 버킷 이름과 업로드할 경로\n",
    "bucket_name = \"jimin-model\"\n",
    "s3_directory = \"two-tower\"\n",
    "\n",
    "# 디렉토리를 tar.gz로 압축하고 S3로 업로드\n",
    "zip_and_upload_to_s3(local_directory, bucket_name, s3_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file('jimin-model', 'two-tower/query_model.tar.gz', 'temp/query_model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp/query_model.tar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "extract_dir = os.path.splitext('temp/query_model.tar.gz')[0]\n",
    "print(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query_model', 'query_model/assets', 'query_model/fingerprint.pb', 'query_model/saved_model.pb', 'query_model/variables', 'query_model/variables/variables.data-00000-of-00001', 'query_model/variables/variables.index']\n"
     ]
    }
   ],
   "source": [
    "# importing the \"tarfile\" module \n",
    "import tarfile \n",
    "  \n",
    "# open file \n",
    "file = tarfile.open('temp/query_model.tar.gz') \n",
    "  \n",
    "# print file names \n",
    "print(file.getnames()) \n",
    "  \n",
    "# extract files \n",
    "file.extractall('./temp') \n",
    "  \n",
    "# close file \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: temp/query_model.tar/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb 셀 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m local_directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtemp\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# 모델 로드\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m load_model_from_s3(bucket_name, s3_file_path, local_directory)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# 예측 함수 추출\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m infer \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39msignatures[\u001b[39m\"\u001b[39m\u001b[39mserving_default\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;32m/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb 셀 27\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m extract_tar_gz(local_tar_gz_file, extract_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# 압축 해제된 모델 로드\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload(extract_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jimin/study/two-tower/2_train_two_tower_model.ipynb#Y101sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_model\n",
      "File \u001b[0;32m~/study/two-tower/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:836\u001b[0m, in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[1;32m    835\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[0;32m--> 836\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    837\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/study/two-tower/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py:941\u001b[0m, in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tags, \u001b[39mset\u001b[39m):\n\u001b[1;32m    937\u001b[0m   \u001b[39m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[1;32m    938\u001b[0m   \u001b[39m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m   tags \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(tags)\n\u001b[1;32m    940\u001b[0m saved_model_proto, debug_info \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 941\u001b[0m     loader_impl\u001b[39m.\u001b[39;49mparse_saved_model_with_debug_info(export_dir))\n\u001b[1;32m    943\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(saved_model_proto\u001b[39m.\u001b[39mmeta_graphs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     saved_model_proto\u001b[39m.\u001b[39mmeta_graphs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mHasField(\u001b[39m\"\u001b[39m\u001b[39mobject_graph_def\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    945\u001b[0m   metrics\u001b[39m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[0;32m~/study/two-tower/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py:58\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[1;32m     46\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m   saved_model \u001b[39m=\u001b[39m parse_saved_model(export_dir)\n\u001b[1;32m     60\u001b[0m   debug_info_path \u001b[39m=\u001b[39m file_io\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     61\u001b[0m       path_helpers\u001b[39m.\u001b[39mget_debug_dir(export_dir),\n\u001b[1;32m     62\u001b[0m       constants\u001b[39m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[1;32m     63\u001b[0m   debug_info \u001b[39m=\u001b[39m graph_debug_info_pb2\u001b[39m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[0;32m~/study/two-tower/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/loader_impl.py:116\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot parse file \u001b[39m\u001b[39m{\u001b[39;00mpath_to_pbtxt\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    117\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSavedModel file does not exist at: \u001b[39m\u001b[39m{\u001b[39;00mexport_dir\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msep\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[39m}\u001b[39;00m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconstants\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: temp/query_model.tar/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import boto3\n",
    "import tensorflow as tf\n",
    "\n",
    "def download_from_s3(bucket_name, s3_file_path, local_directory):\n",
    "    local_file_path = os.path.join(local_directory, os.path.basename(s3_file_path))\n",
    "    s3_client.download_file(bucket_name, s3_file_path, local_directory)\n",
    "    return local_file_path\n",
    "\n",
    "def extract_tar_gz(tar_gz_file, extract_dir):\n",
    "    with tarfile.open(tar_gz_file, \"r:gz\") as tar:\n",
    "        tar.extractall(path=extract_dir)\n",
    "\n",
    "def load_model_from_s3(bucket_name, s3_file_path, local_directory):\n",
    "    # S3에서 tar.gz 파일 다운로드\n",
    "    # local_tar_gz_file = download_from_s3(bucket_name, s3_file_path, local_directory)\n",
    "    # print(local_tar_gz_file)\n",
    "    local_tar_gz_file = 'temp/query_model.tar.gz'\n",
    "\n",
    "    # tar.gz 파일 압축 해제\n",
    "    extract_dir = os.path.splitext(local_tar_gz_file)[0]\n",
    "    extract_tar_gz(local_tar_gz_file, extract_dir)\n",
    "\n",
    "    # 압축 해제된 모델 로드\n",
    "    loaded_model = tf.saved_model.load(extract_dir)\n",
    "\n",
    "    return loaded_model\n",
    "\n",
    "# S3 버킷 이름과 파일 경로\n",
    "bucket_name = \"jimin-model\"\n",
    "s3_file_path = \"two-tower/query_model.tar.gz\"\n",
    "\n",
    "# 로컬에 저장될 디렉토리 경로\n",
    "local_directory = \"temp\"\n",
    "\n",
    "# 모델 로드\n",
    "loaded_model = load_model_from_s3(bucket_name, s3_file_path, local_directory)\n",
    "\n",
    "# 예측 함수 추출\n",
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "# 입력 스펙 확인\n",
    "# print(infer.structured_input_signature)\n",
    "\n",
    "# 샘플 입력 데이터 생성 (double 타입으로)\n",
    "sample_input = {\n",
    "    'customer_id': tf.constant(['customer1', 'customer2']),\n",
    "    'month_sin': tf.constant([0.1, 0.2], dtype=tf.float64),\n",
    "    'month_cos': tf.constant([0.2, 0.3], dtype=tf.float64),\n",
    "    'age': tf.constant([30.0, 40.0], dtype=tf.float64)\n",
    "}\n",
    "\n",
    "# 예측 수행\n",
    "predictions = infer(**sample_input)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
